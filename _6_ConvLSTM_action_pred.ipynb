{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4231cfd",
   "metadata": {},
   "source": [
    "# Convolutional LSTM for action prediction\n",
    "\n",
    "- keep track of best validation value + Save checkpoints with information (autosave)\n",
    "- clean naming (of how models are saved, configs are saved, runs are called)\n",
    "- confusion matrix of result / comparison with baseline LSTM (that only takes in actions)\n",
    "- wandb/ tensorboard integration (also for gradient information?)\n",
    "- hydra integration for hyperparameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7db80c6",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7fe3d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariuskaestingschaefer/miniforge3/envs/pytorch/lib/python3.8/site-packages/seaborn/rcmod.py:82: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(mpl.__version__) >= \"3.0\":\n",
      "/Users/mariuskaestingschaefer/miniforge3/envs/pytorch/lib/python3.8/site-packages/setuptools/_distutils/version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import hydra\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.autograd import Variable\n",
    "from torchinfo import summary\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "# own\n",
    "import common.action as action\n",
    "import common.world as world\n",
    "import common.plot as plot\n",
    "import common.preprocess as preprocess\n",
    "import common.nets as nets\n",
    "import common.train as train\n",
    "import common.tools as tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb3400d",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5a9b473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input size is 960 or 1\n",
    "train_imgs        = True\n",
    "save_infos        = False\n",
    "\n",
    "# preprocessing\n",
    "seq_length        = 20\n",
    "training_set_size = 0.67\n",
    "\n",
    "# lstm configuration\n",
    "hidden_size       = 20\n",
    "num_layers        = 1\n",
    "num_classes       = 4\n",
    "save_model        = False\n",
    "    \n",
    "# training\n",
    "num_epochs        = 2000\n",
    "learning_rate     = 0.01\n",
    "optimizer_type    = 'Adam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42cfa6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_imgs:\n",
    "    input_size = 960\n",
    "else:\n",
    "    input_size = 1\n",
    "\n",
    "if num_classes == 1:\n",
    "    hot_encoding=False\n",
    "elif num_classes ==4:\n",
    "    hot_encoding=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bd26ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params:\n",
      "  train_imgs: false\n",
      "  save_infos: false\n",
      "  dataset_name: None\n",
      "  seq_length: 20\n",
      "  batch_size: 128\n",
      "  training_set_size: 0.67\n",
      "  hidden_size: 20\n",
      "  num_layers: 1\n",
      "  num_classes: 4\n",
      "  input_size: 1\n",
      "  num_epochs: 2000\n",
      "  learning_rate: 0.01\n",
      "  optimizer_type: Adam\n",
      "  save_model: false\n",
      "  save_plots: false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# hydra integration for hyperparameters\n",
    "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "\n",
    "hydra.initialize(version_base=None, config_path='conf') # Assume the configuration file is in the current folder\n",
    "cfg = hydra.compose(config_name='config')\n",
    "# Can be used in the following way: cfg.params.learning_rate \n",
    "print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d309342f",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c755f857",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datasets/oracle_data.pickle', 'rb') as handle:\n",
    "    oracle_data = pickle.load(handle)\n",
    "\n",
    "with open('datasets/oracle_reversed_data.pickle', 'rb') as handle:\n",
    "    oracle_reversed_data = pickle.load(handle)\n",
    "\n",
    "with open('datasets/oracle_random_data.pickle', 'rb') as handle:\n",
    "    oracle_random_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8b6af1",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5db2437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess with sequence length\n",
    "x_acts, x_imgs, y_acts = preprocess.sliding_windows(oracle_data, seq_length, hot_encoding)\n",
    "# data, train, test split\n",
    "data, train, test = preprocess.split(x_acts, x_imgs, y_acts, training_set_size)\n",
    "dataX_acts, dataX_imgs, dataY_acts = data\n",
    "trainX_acts, trainX_imgs, trainY_acts = train\n",
    "testX_acts, testX_imgs, testY_acts = test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41240b5d",
   "metadata": {},
   "source": [
    "### Initialize models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae5c0ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariuskaestingschaefer/miniforge3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN input shape: torch.Size([786, 20, 3, 32, 32])\n",
      "CNN output shape: torch.Size([786, 20, 960])\n",
      "LSTM input shape: torch.Size([786, 20, 960])\n",
      "LSTM output shape: torch.Size([786, 4])\n",
      "Label shape: torch.Size([786, 4])\n",
      "SUMMARY CNN \n",
      " ==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "CNN                                      [786, 20, 960]            --\n",
      "├─Conv2d: 1-1                            [15720, 20, 28, 28]       1,520\n",
      "├─Conv2d: 1-2                            [15720, 40, 24, 24]       20,040\n",
      "├─MaxPool2d: 1-3                         [15720, 40, 12, 12]       --\n",
      "├─Conv2d: 1-4                            [15720, 60, 8, 8]         60,060\n",
      "├─MaxPool2d: 1-5                         [15720, 60, 4, 4]         --\n",
      "==========================================================================================\n",
      "Total params: 81,620\n",
      "Trainable params: 81,620\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 260.61\n",
      "==========================================================================================\n",
      "Input size (MB): 193.17\n",
      "Forward/backward pass size (MB): 5352.35\n",
      "Params size (MB): 0.33\n",
      "Estimated Total Size (MB): 5545.84\n",
      "========================================================================================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnn = nets.CNN(seq_length)\n",
    "lstm = nets.LSTM(num_classes, input_size, hidden_size, num_layers, seq_length)\n",
    "\n",
    "if train_imgs:\n",
    "    features = cnn(trainX_imgs)\n",
    "else:\n",
    "    features = trainX_acts\n",
    "\n",
    "outputs = lstm(features)\n",
    "\n",
    "print('CNN input shape:', trainX_imgs.size())\n",
    "print('CNN output shape:', features.size())\n",
    "\n",
    "print('LSTM input shape:', features.size())\n",
    "print('LSTM output shape:', outputs.size())\n",
    "\n",
    "print('Label shape:', trainY_acts.size())\n",
    "\n",
    "print('SUMMARY CNN \\n', summary(cnn, trainX_imgs.size()), '\\n')\n",
    "#print('SUMMARY LSTM \\n', summary(lstm, (outputs.size(), ((2, 10), (2, 10,)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c801f99b",
   "metadata": {},
   "source": [
    "### Tensorboard integrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3575df5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-bd942a68ba3b950d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-bd942a68ba3b950d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d402f0",
   "metadata": {},
   "source": [
    "### Network training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7749c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Print model\\'s state_dict\\nprint(\"Model\\'s state_dict:\")\\nfor param_tensor in DualInput_model.state_dict():\\n    print(param_tensor, \"\\t\", DualInput_model.state_dict()[param_tensor].size())\\n\\n# Print optimizer\\'s state_dict\\nprint(\"\\nOptimizer\\'s state_dict:\")\\nfor var_name in optimizer.state_dict():\\n    print(var_name, \"\\t\", optimizer.state_dict()[var_name])\\n    \\ncnn = nets.CNN(seq_length)\\n\\nprint(trainX_imgs[0])\\nfeatures = cnn(trainX_imgs)\\nprint(\\'features\\', features[0])\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wandb and tensorboard integration\n",
    "# write model summary/ parameter settings into runs folder\n",
    "\n",
    "# track best validation value\n",
    "# save model during training\n",
    "\n",
    "# full batch training likely is too slow (?)\n",
    "\"\"\"\n",
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in DualInput_model.state_dict():\n",
    "    print(param_tensor, \"\\t\", DualInput_model.state_dict()[param_tensor].size())\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"\\nOptimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])\n",
    "    \n",
    "cnn = nets.CNN(seq_length)\n",
    "\n",
    "print(trainX_imgs[0])\n",
    "features = cnn(trainX_imgs)\n",
    "print('features', features[0])\n",
    "\"\"\"\n",
    "# problem: with the imgs the loss does never decrease below 0.27\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd7ab2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recode_values(outputs):\n",
    "\n",
    "    # max threshold, absolut\n",
    "    adopted_output = [abs(output.detach().cpu().numpy()[0]) * (output.detach().cpu().numpy() >= max(output.detach().cpu().numpy())) for output in outputs]\n",
    "    # all values 0 or 1, make it a tensor again to make np.where work\n",
    "    adopted_output = torch.FloatTensor([list(np.where(variable > 0, 1, 0)) for variable in adopted_output])\n",
    "    # reverse the original coding to get a single int again\n",
    "    adopted_output = [np.where(data==1)[0][0] for data in adopted_output] #\n",
    "    \n",
    "    return adopted_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd95935c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_correct(new_data_predict, dataY_plot):\n",
    "    new_dataY_plot = [np.where(r==1)[0][0] for r in dataY_plot]\n",
    "    counter = 0\n",
    "    for i in range(len(new_data_predict)):\n",
    "        if new_data_predict[i] == new_dataY_plot[i]:\n",
    "            counter += 1\n",
    "    return counter\n",
    "\n",
    "def compute_acc(outputs, labels):\n",
    "    outputs = recode_values(outputs)\n",
    "    correct = compute_correct(outputs, labels)\n",
    "    acc = correct / len(outputs)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f84d5212",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc91583a52d34392942ea2ab37ae7bfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress:   0%|          | 0/10 [00:00<?, ? Episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0000 - Train Loss: 0.777, Train Acc: 0.824 - Test Loss: 0.755, Test Acc: 0.845\n",
      "Epoch: 0001 - Train Loss: 0.753, Train Acc: 0.824 - Test Loss: 0.728, Test Acc: 0.845\n",
      "Epoch: 0002 - Train Loss: 0.735, Train Acc: 0.824 - Test Loss: 0.707, Test Acc: 0.845\n",
      "Epoch: 0003 - Train Loss: 0.721, Train Acc: 0.824 - Test Loss: 0.691, Test Acc: 0.845\n",
      "Epoch: 0004 - Train Loss: 0.712, Train Acc: 0.824 - Test Loss: 0.679, Test Acc: 0.845\n",
      "Epoch: 0005 - Train Loss: 0.706, Train Acc: 0.824 - Test Loss: 0.671, Test Acc: 0.845\n",
      "Epoch: 0006 - Train Loss: 0.701, Train Acc: 0.824 - Test Loss: 0.665, Test Acc: 0.845\n",
      "Epoch: 0007 - Train Loss: 0.699, Train Acc: 0.824 - Test Loss: 0.661, Test Acc: 0.845\n",
      "Epoch: 0008 - Train Loss: 0.697, Train Acc: 0.824 - Test Loss: 0.658, Test Acc: 0.845\n",
      "Epoch: 0009 - Train Loss: 0.695, Train Acc: 0.824 - Test Loss: 0.656, Test Acc: 0.845\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "if train_imgs:\n",
    "    params = list(cnn.parameters()) + list(lstm.parameters())\n",
    "else:\n",
    "    params = lstm.parameters()\n",
    "\n",
    "# MSELoss - regression, CrossEntropyLoss for labels or BCEWithLogitsLoss\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "if optimizer_type == 'Adam':\n",
    "    optimizer = torch.optim.Adam(params, lr=learning_rate)\n",
    "elif optimizer_type == 'SGD':\n",
    "    optimizer = torch.optim.SGD(params, lr=learning_rate, momentum=0.9)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "# save current conf infos\n",
    "if save_infos:\n",
    "    local_time = str(datetime.datetime.now().isoformat())\n",
    "    name = local_time + '_configs'\n",
    "    OmegaConf.save(cfg, \"runs/\"+name)\n",
    "\n",
    "with tqdm(total=num_epochs, unit =\" Episode\", desc =\"Progress\") as pbar:\n",
    "    \n",
    "    # tracking results\n",
    "    train_loss_lst, test_loss_lst = [], []\n",
    "    train_acc_lst, test_acc_lst = [], []\n",
    "    test_best_acc = 100\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # choose training style\n",
    "            if train_imgs:\n",
    "                features = cnn(testX_imgs)\n",
    "            else:\n",
    "                features = testX_acts\n",
    "            outputs = lstm(features)\n",
    "            \n",
    "            # loss\n",
    "            loss_test = criterion(outputs, testY_acts)\n",
    "            \n",
    "            # compute train acc\n",
    "            acc_test = compute_acc(outputs, testY_acts)\n",
    "        \n",
    "        # choose training style\n",
    "        if train_imgs:\n",
    "            features = cnn(trainX_imgs) # forwarad pass of the cnn\n",
    "        else:\n",
    "            features = trainX_acts\n",
    "        \n",
    "        # forwarad pass of the lstm\n",
    "        outputs = lstm(features)\n",
    "        optimizer.zero_grad() # zero the parameter gradients\n",
    "\n",
    "        # loss + optimize\n",
    "        loss_train = criterion(outputs, trainY_acts)\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # compute train acc\n",
    "        acc_train = compute_acc(outputs, trainY_acts)\n",
    "            \n",
    "        # display\n",
    "        if epoch % (num_epochs/10) == 0:\n",
    "            epoch = (4 - len(str(epoch)))*str(0) + str(epoch)                 \n",
    "            print(\"Epoch: %s - Train Loss: %1.3f, Train Acc: %1.3g - Test Loss: %1.3f, Test Acc: %1.3g\" % (epoch, loss_train.item(), acc_train, loss_test.item(), acc_test))\n",
    "        \n",
    "        # collect tensorboard logs\n",
    "        \n",
    "        # collect plotting logs\n",
    "        train_loss_lst.append(loss_train.item())\n",
    "        test_loss_lst.append(loss_test.item())\n",
    "        train_acc_lst.append(acc_train)\n",
    "        test_acc_lst.append(acc_test)\n",
    "            \n",
    "        pbar.update(1)\n",
    "    \n",
    "    writer.close()\n",
    "    print('Finished Training')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81135a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_losses(train_loss_lst, test_loss_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda4a26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_acc(train_acc_lst, test_acc_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f034f4a3",
   "metadata": {},
   "source": [
    "### Plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434fb021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recode_one_hot(data_predict):\n",
    "    new_data_predict = []\n",
    "    for i in data_predict:\n",
    "        if str(i) != '[0. 0. 0. 0.]':\n",
    "            new_data_predict.append(np.where(i==1)[0][0])\n",
    "        else:\n",
    "            new_data_predict.append(None)\n",
    "    return new_data_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3da87ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "lstm.eval()\n",
    "\n",
    "if train_imgs:\n",
    "    features = cnn(dataX_imgs)\n",
    "    features = features #+ 0.01*trainX_acts\n",
    "    train_predict = lstm(features)\n",
    "else:\n",
    "    train_predict = lstm(dataX_acts)\n",
    "\n",
    "'''\n",
    "t = Variable(torch.Tensor([0]))  # threshold\n",
    "data_predict = (train_predict > t).float() * 1\n",
    "\n",
    "new_data_predict = recode_one_hot(data_predict)\n",
    "#data_predict = train_predict.data.numpy()\n",
    "'''\n",
    "\n",
    "new_data_predict = recode_values(train_predict)\n",
    "\n",
    "dataY_plot = dataY_acts.data.numpy()\n",
    "new_dataY_plot = [np.where(r==1)[0][0] for r in dataY_plot]\n",
    "\n",
    "with plt.style.context('ggplot'):\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    plt.axvline(int(len(y_acts) * training_set_size), c='r', linestyle='--')\n",
    "    plt.text(int(len(y_acts) * training_set_size)+10, 1.5, \"train-test split\", rotation=90, verticalalignment='center')\n",
    "\n",
    "    plt.plot(new_dataY_plot, 'o', color='slategray', markersize=10, label=\"Actual actions\")\n",
    "    plt.plot(new_data_predict, 'o', markersize=5, label=\"Predicted actions\")\n",
    "    \n",
    "    #locs, labels = plt.yticks()\n",
    "    plt.yticks([0, 1, 2], ['Turn left', 'Turn right', 'Move forwards'])\n",
    "    \n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.title('Action sequence prediction')\n",
    "    plt.xlabel('Sequence')\n",
    "    plt.ylabel('Action')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3750533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show that it isn't the LSTM that is broken\n",
    "\n",
    "# and it would be weird if it would be the CNN architecture, since this one worked alone as well\n",
    "# use diff. image to obtain action and continue from their to prediction next action\n",
    "\n",
    "# reasons why it does not work: images not normalized\n",
    "# seems like convolutional network and LSTM do not interact properly with one another (?!)\n",
    "\n",
    "# possible to change architecture?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff5d211",
   "metadata": {},
   "source": [
    "### Plot loss and accuracy curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacf262e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look into confusion matrix\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_m1",
   "language": "python",
   "name": "pytorch_m1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
