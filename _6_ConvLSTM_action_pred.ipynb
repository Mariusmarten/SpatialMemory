{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4231cfd",
   "metadata": {},
   "source": [
    "# Convolutional LSTM for action prediction\n",
    "\n",
    "- keep track of best validation value + Save checkpoints with information (autosave)\n",
    "- clean naming (of how models are saved, configs are saved, runs are called)\n",
    "- confusion matrix of result / comparison with baseline LSTM (that only takes in actions)\n",
    "- wandb/ tensorboard integration (also for gradient information?)\n",
    "- hydra integration for hyperparameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c14c30",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e8a92b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "seq_length = 20\n",
    "training_set_size = 0.67\n",
    "\n",
    "# lstm configuration\n",
    "input_size = 960\n",
    "hidden_size = 20\n",
    "num_layers = 1\n",
    "num_classes = 1\n",
    "\n",
    "# training\n",
    "num_epochs = 2000\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a15971",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b40d4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariuskaestingschaefer/miniforge3/envs/pytorch/lib/python3.8/site-packages/seaborn/rcmod.py:82: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(mpl.__version__) >= \"3.0\":\n",
      "/Users/mariuskaestingschaefer/miniforge3/envs/pytorch/lib/python3.8/site-packages/setuptools/_distutils/version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n",
      "/Users/mariuskaestingschaefer/miniforge3/envs/pytorch/lib/python3.8/site-packages/torch/utils/tensorboard/__init__.py:6: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, '__version__') or LooseVersion(tensorboard.__version__) < LooseVersion('1.15'):\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import hydra\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchinfo import summary\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# own\n",
    "import common.action as action\n",
    "import common.world as world\n",
    "import common.plot as plot\n",
    "import common.preprocess as preprocess\n",
    "import common.nets as nets\n",
    "import common.train as train\n",
    "import common.tools as tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d309342f",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c755f857",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datasets/oracle_data.pickle', 'rb') as handle:\n",
    "    oracle_data = pickle.load(handle)\n",
    "\n",
    "with open('datasets/oracle_reversed_data.pickle', 'rb') as handle:\n",
    "    oracle_reversed_data = pickle.load(handle)\n",
    "\n",
    "with open('datasets/oracle_random_data.pickle', 'rb') as handle:\n",
    "    oracle_random_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8b6af1",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5db2437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_windows(dataset, seq_length):    \n",
    "    x_actions = []\n",
    "    y_actions = []\n",
    "\n",
    "    actions = dataset['actions']\n",
    "    imgs = dataset['observations']\n",
    "    \n",
    "    # preprocess actions\n",
    "    actions = [[i] for i in actions]\n",
    "    \n",
    "    # preprocess images\n",
    "    x_imgs = []\n",
    "    for img in imgs:\n",
    "        img = torch.from_numpy(img).float()\n",
    "        img = img.permute(2, 0, 1)\n",
    "        x_imgs.append(img)\n",
    "    x_imgs_processed = torch.stack(x_imgs)\n",
    "    \n",
    "    # actual sliding window\n",
    "    x_imgs = []\n",
    "    for i in range(len(actions)-seq_length-1):\n",
    "        _x_actions = actions[i:(i+seq_length)]\n",
    "        _x_imgs = x_imgs_processed[i:(i+seq_length)]\n",
    "        _y_actions = actions[i+1+seq_length] # _y = data[i+seq_length]\n",
    "        \n",
    "        x_actions.append(_x_actions)\n",
    "        x_imgs.append(_x_imgs)\n",
    "        y_actions.append(_y_actions)\n",
    "        \n",
    "    x_imgs = torch.stack(x_imgs)\n",
    "\n",
    "    return np.array(x_actions), x_imgs, np.array(y_actions) # train, val. data\n",
    "\n",
    "x_acts, x_imgs, y_acts = sliding_windows(oracle_data, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a6a3717",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "train_size = int(len(y_acts) * training_set_size)\n",
    "test_size = len(y_acts) - train_size\n",
    "\n",
    "# (full) data set\n",
    "dataX_acts = Variable(torch.Tensor(np.array(x_acts)))\n",
    "dataX_imgs = Variable(torch.Tensor(x_imgs))\n",
    "dataY_acts = Variable(torch.Tensor(np.array(y_acts)))\n",
    "\n",
    "# training set\n",
    "trainX_acts = Variable(torch.Tensor(np.array(x_acts[0:train_size])))\n",
    "trainX_imgs = Variable(torch.Tensor(np.array(x_imgs[0:train_size])))\n",
    "trainY_acts = Variable(torch.Tensor(np.array(y_acts[0:train_size])))\n",
    "\n",
    "# validation set\n",
    "testX_acts = Variable(torch.Tensor(np.array(x_acts[train_size:len(x_acts)])))\n",
    "testX_imgs = Variable(torch.Tensor(np.array(x_imgs[train_size:len(x_imgs)])))\n",
    "testY_acts = Variable(torch.Tensor(np.array(y_acts[train_size:len(y_acts)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fe7bdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.seq_length = seq_length\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                            num_layers=num_layers, batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # newly initialized only after each epoch\n",
    "        h_0 = Variable(torch.zeros(\n",
    "            self.num_layers, x.size(0), self.hidden_size))\n",
    "        c_0 = Variable(torch.zeros(\n",
    "            self.num_layers, x.size(0), self.hidden_size))\n",
    "        \n",
    "        # Propagate input through LSTM\n",
    "        ula, (h_out, _) = self.lstm(x, (h_0, c_0))\n",
    "        h_out = h_out.view(-1, self.hidden_size)\n",
    "        out = self.fc(h_out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ed57abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, seq_length):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, seq_length, 5)\n",
    "        self.conv2 = nn.Conv2d(seq_length, seq_length*2, 5)\n",
    "        self.conv3 = nn.Conv2d(seq_length*2, seq_length*3, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "    def forward(self, i):\n",
    "        x = i.reshape(-1, i.shape[2], i.shape[3], i.shape[4]) # merges batch and length dimension\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(i.shape[0], i.shape[1], -1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07d2b0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN input shape: torch.Size([786, 20, 3, 32, 32])\n",
      "CNN output shape: torch.Size([786, 20, 960])\n",
      "LSTM input shape: torch.Size([786, 20, 960])\n",
      "LSTM output shape: torch.Size([786, 1])\n",
      "Label shape: torch.Size([786, 1])\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN(seq_length)\n",
    "\n",
    "input_size = 960\n",
    "\n",
    "lstm = LSTM(num_classes, input_size, hidden_size, num_layers)\n",
    "\n",
    "features = cnn(trainX_imgs)\n",
    "outputs = lstm(features)\n",
    "\n",
    "print('CNN input shape:', trainX_imgs.size())\n",
    "print('CNN output shape:', features.size())\n",
    "\n",
    "print('LSTM input shape:', features.size())\n",
    "print('LSTM output shape:', outputs.size())\n",
    "\n",
    "print('Label shape:', trainY_acts.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f1682a",
   "metadata": {},
   "source": [
    "### Network training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0865f125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 3.16080\n",
      "Epoch: 200, loss: 0.14590\n",
      "Epoch: 400, loss: 0.13812\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# obtain the loss function\u001b[39;00m\n\u001b[1;32m     18\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, trainY_acts)\n\u001b[0;32m---> 20\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.8/site-packages/torch/_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    300\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    301\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    305\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    306\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 307\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.8/site-packages/torch/autograd/__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m--> 154\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_size = 1\n",
    "lstm = LSTM(num_classes, input_size, hidden_size, num_layers)\n",
    "\n",
    "criterion = torch.nn.MSELoss() # MSELoss - regression, CrossEntropyLoss for labels\n",
    "#params = list(cnn.parameters()) + list(lstm.parameters())\n",
    "#optimizer = torch.optim.Adam(params, lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n",
    "\n",
    "# full batch training likely is too slow!\n",
    "for epoch in range(num_epochs):\n",
    "    #features = net_cnn(trainX_imgs)\n",
    "    #features = features #+ 0.01*trainX_acts\n",
    "    features = trainX_acts\n",
    "    outputs = lstm(features)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # obtain the loss function\n",
    "    loss = criterion(outputs, trainY_acts)\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    if epoch % 200 == 0:\n",
    "        print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a218535",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss() # MSELoss - regression, CrossEntropyLoss for labels\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    outputs = lstm(trainX_acts) # we do not need to pass around the states since we train full batch\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # obtain the loss function\n",
    "    loss = criterion(outputs, trainY_acts)\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    if epoch % 200 == 0:\n",
    "        print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550f3a10",
   "metadata": {},
   "source": [
    "### Plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c43d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "lstm.eval()\n",
    "train_predict = lstm(dataX_acts)\n",
    "\n",
    "data_predict = train_predict.data.numpy()\n",
    "dataY_plot = dataY_acts.data.numpy()\n",
    "\n",
    "#data_predict = sc.inverse_transform(data_predict)\n",
    "#dataY_plot = sc.inverse_transform(dataY_plot)\n",
    "\n",
    "plt.axvline(x=train_size, c='r', linestyle='--')\n",
    "\n",
    "plt.plot(dataY_plot, 'o', markersize=10)\n",
    "plt.plot(data_predict, 'o', markersize=5)\n",
    "plt.suptitle('Time-Series Prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219f9cf3",
   "metadata": {},
   "source": [
    "### Initialize models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b073691f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/52138290/how-can-we-define-one-to-one-one-to-many-many-to-one-and-many-to-many-lstm-ne\n",
    "\n",
    "# enable model to work with different sequence lengths\n",
    "# wandb and tensorboard integration\n",
    "\n",
    "# write model summary into runs folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc43af6a",
   "metadata": {},
   "source": [
    "### Tensorboard integrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1391182",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7c7f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hydra integration for hyperparameters\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "import datetime\n",
    "\n",
    "\n",
    "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "\n",
    "hydra.initialize(version_base=None, config_path='conf') # Assume the configuration file is in the current folder\n",
    "cfg = hydra.compose(config_name='config')\n",
    "\n",
    "print(cfg)\n",
    "print(cfg.params.lr)\n",
    "\n",
    "print(OmegaConf.to_yaml(cfg))\n",
    "\n",
    "local_time = str(datetime.datetime.now().isoformat())\n",
    "name = local_time + '_configs'\n",
    "OmegaConf.save(cfg, \"runs/\"+name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d724c9",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69398ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# track best validation value\n",
    "# save model during training\n",
    "\n",
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in DualInput_model.state_dict():\n",
    "    print(param_tensor, \"\\t\", DualInput_model.state_dict()[param_tensor].size())\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"\\nOptimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff5d211",
   "metadata": {},
   "source": [
    "### Plot loss and accuracy curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacf262e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look into confusion matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_m1",
   "language": "python",
   "name": "pytorch_m1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
