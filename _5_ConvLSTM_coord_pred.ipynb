{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ebf1809",
   "metadata": {},
   "source": [
    "# Convolutional LSTM for coordinate prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc293a19",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbd37259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchinfo import summary\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# own\n",
    "import common.action as action\n",
    "import common.world as world\n",
    "import common.plot as plot\n",
    "import common.preprocess as preprocess\n",
    "import common.nets as nets\n",
    "import common.train as train\n",
    "import common.tools as tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43c8112",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68951bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets/oracle_data.pickle\", \"rb\") as handle:\n",
    "    oracle_data = pickle.load(handle)\n",
    "\n",
    "with open(\"datasets/oracle_reversed_data.pickle\", \"rb\") as handle:\n",
    "    oracle_reversed_data = pickle.load(handle)\n",
    "\n",
    "with open(\"datasets/oracle_random_data.pickle\", \"rb\") as handle:\n",
    "    oracle_random_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1450d4",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca7acbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "length_trajectory = 10\n",
    "batch_size = 128\n",
    "\n",
    "# split and shuffle data\n",
    "train_data, test_data = preprocess.split_data_for_trajectories(\n",
    "    oracle_reversed_data, 0.8, length_trajectory\n",
    ")\n",
    "train_imgs, train_pos = preprocess.process_trajectory(train_data)\n",
    "test_imgs, test_pos = preprocess.process_trajectory(test_data)\n",
    "\n",
    "# stage data for the DataLoader\n",
    "train_data = preprocess.ObtainDataset_notransform(train_imgs, train_pos)\n",
    "test_data = preprocess.ObtainDataset_notransform(test_imgs, test_pos)\n",
    "\n",
    "# DataLoader\n",
    "dataset_loader_train_data = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "dataset_loader_test_data = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3691f1c2",
   "metadata": {},
   "source": [
    "### Initialize models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b32fed10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input cnn: torch.Size([128, 10, 3, 32, 32]) - Batch size, Channel out, Height out, Width out\n",
      "output cnn: torch.Size([128, 10, 480])  - Batch size, sequence length, input size\n",
      "input lstm: torch.Size([128, 10, 480])  - Batch size, sequence length, input size\n",
      "hidden lstm: torch.Size([10, 100])\n",
      "output lstm: torch.Size([128, 1]) \n",
      "\n",
      "SUMMARY CNN \n",
      " ==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "CNN_coords                               [128, 10, 480]            --\n",
      "├─Conv2d: 1-1                            [1280, 10, 28, 28]        760\n",
      "├─Conv2d: 1-2                            [1280, 20, 24, 24]        5,020\n",
      "├─MaxPool2d: 1-3                         [1280, 20, 12, 12]        --\n",
      "├─Conv2d: 1-4                            [1280, 30, 8, 8]          15,030\n",
      "├─MaxPool2d: 1-5                         [1280, 30, 4, 4]          --\n",
      "==========================================================================================\n",
      "Total params: 20,810\n",
      "Trainable params: 20,810\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 5.70\n",
      "==========================================================================================\n",
      "Input size (MB): 15.73\n",
      "Forward/backward pass size (MB): 217.91\n",
      "Params size (MB): 0.08\n",
      "Estimated Total Size (MB): 233.72\n",
      "========================================================================================== \n",
      "\n",
      "SUMMARY LSTM \n",
      " ==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "LSTM_coords                              [128, 1]                  --\n",
      "├─LSTM: 1-1                              [128, 10, 100]            313,600\n",
      "├─Linear: 1-2                            [128, 84]                 84,084\n",
      "├─Linear: 1-3                            [128, 84]                 (recursive)\n",
      "├─Linear: 1-4                            [128, 1]                  85\n",
      "├─Linear: 1-5                            [128, 1]                  (recursive)\n",
      "==========================================================================================\n",
      "Total params: 397,769\n",
      "Trainable params: 397,769\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 422.96\n",
      "==========================================================================================\n",
      "Input size (MB): 2.47\n",
      "Forward/backward pass size (MB): 1.11\n",
      "Params size (MB): 1.59\n",
      "Estimated Total Size (MB): 5.18\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# initialize network\n",
    "net_cnn = nets.CNN_coords()\n",
    "net_lstm = nets.LSTM_coords(length_trajectory)\n",
    "\n",
    "# initial values\n",
    "h0 = torch.randn(2, 10, 100)\n",
    "c0 = torch.randn(2, 10, 100)\n",
    "x = torch.rand((batch_size, 10, 3, 32, 32))\n",
    "\n",
    "# check network\n",
    "features = net_cnn(x)\n",
    "out0, out1, hidden, c = net_lstm(features, h0, c0)\n",
    "\n",
    "# shape statistics\n",
    "tools.shapes(x, features, hidden, out0)\n",
    "\n",
    "# network summary\n",
    "print(\"SUMMARY CNN \\n\", summary(net_cnn, (batch_size, 10, 3, 32, 32)), \"\\n\")\n",
    "print(\"SUMMARY LSTM \\n\", summary(net_lstm, ((batch_size, 10, 480), (2, 10, 100), (2, 10, 100))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ebf0c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "print(len(out0))\n",
    "print(len(out1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7350f086",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len label 10\n",
      "[array([ 9.72609095,  0.        , 21.41735139]), array([ 9.57611305,  0.        , 21.41477643]), array([ 9.42613515,  0.        , 21.41220146]), array([ 9.27615726,  0.        , 21.40962649]), array([ 9.12617936,  0.        , 21.40705153]), array([ 8.97620146,  0.        , 21.40447656]), array([ 8.82622356,  0.        , 21.40190159]), array([ 8.67624567,  0.        , 21.39932662]), array([ 8.52626777,  0.        , 21.39675166]), array([ 8.37628987,  0.        , 21.39417669])]\n",
      "10\n",
      "128\n",
      "tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.0788, 0.0358, 0.0690],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0818, 0.0445, 0.0410],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0249, 0.0453, 0.0950],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0472, 0.0569, 0.0500],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0534, 0.0738, 0.0513],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0628, 0.0556, 0.0293]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 0.0623, 0.0413, 0.0469],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0659, 0.0412, 0.0410],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0752, 0.0735, 0.0379],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0476, 0.0475, 0.0524],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0719, 0.0508, 0.0420],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0627, 0.0329, 0.0654]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 0.0600, 0.0607, 0.0381],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0495, 0.0553, 0.0589],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0728, 0.0506, 0.0689],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0637, 0.0535, 0.0486],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0386, 0.0711, 0.0491],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0423, 0.0414, 0.0655]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 0.0210, 0.0555, 0.0391],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0510, 0.0483, 0.0749],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0565, 0.0627, 0.0521],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0568, 0.0465, 0.0278],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0702, 0.0760, 0.0519],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0617, 0.0523, 0.0496]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 0.0536, 0.0598, 0.0291],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0526, 0.0704, 0.0447],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0604, 0.0695, 0.0558],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0609, 0.0533, 0.0742],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0742, 0.0578, 0.0362],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0668, 0.0712, 0.0586]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 0.0536, 0.0111, 0.0540],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0708, 0.0555, 0.0567],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0447, 0.0568, 0.0526],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0556, 0.0740, 0.0460],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0728, 0.0218, 0.0763],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0310, 0.0565, 0.0562]]],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "inputs, label = next(iter(train_data))\n",
    "\n",
    "#print('inputs', inputs)\n",
    "print('len label', len(label))\n",
    "\n",
    "print(label)\n",
    "\n",
    "\n",
    "print(len(inputs))\n",
    "inputs = torch.stack(inputs)\n",
    "inputs = torch.swapaxes(inputs, 0, 1)\n",
    "print(len(x))\n",
    "\n",
    "net_cnn = nets.CNN_coords()\n",
    "\n",
    "encoded = net_cnn(x)\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ceed954",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed57693a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f0d7f40de804b5384f51fc890b3ae5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress:   0%|          | 0/500 [00:00<?, ? Episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariuskaestingschaefer/miniforge3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([128, 10])) that is different to the input size (torch.Size([128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (128) must match the size of tensor b (10) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(params, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m      4\u001b[0m episodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m\n\u001b[1;32m      6\u001b[0m (\n\u001b[1;32m      7\u001b[0m     train_loss,\n\u001b[1;32m      8\u001b[0m     test_loss,\n\u001b[1;32m      9\u001b[0m     train_dis,\n\u001b[1;32m     10\u001b[0m     test_dis,\n\u001b[1;32m     11\u001b[0m     train_dis_item,\n\u001b[1;32m     12\u001b[0m     test_dis_item,\n\u001b[0;32m---> 13\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_ConvLSTM\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_loader_train_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_loader_test_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnet_cnn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnet_lstm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepisodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlength_trajectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/StateInfoGain/common/train.py:493\u001b[0m, in \u001b[0;36mtrain_ConvLSTM\u001b[0;34m(train_data, val_data, net_cnn, net_lstm, criterion, optimizer, steps, length_trajectory)\u001b[0m\n\u001b[1;32m    490\u001b[0m outputs_B \u001b[38;5;241m=\u001b[39m outputs_B\u001b[38;5;241m.\u001b[39mdouble()\n\u001b[1;32m    492\u001b[0m \u001b[38;5;66;03m# compute losses separatel\u001b[39;00m\n\u001b[0;32m--> 493\u001b[0m loss_A \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs_A\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_A\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m loss_B \u001b[38;5;241m=\u001b[39m criterion(outputs_B\u001b[38;5;241m.\u001b[39msqueeze(), labels_B)\n\u001b[1;32m    496\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_A \u001b[38;5;241m+\u001b[39m loss_B\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/loss.py:520\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:3111\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3109\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3111\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mmse_loss(expanded_input, expanded_target, _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction))\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.8/site-packages/torch/functional.py:72\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tensors):\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[38;5;241m*\u001b[39mtensors)\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (128) must match the size of tensor b (10) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "params = list(net_cnn.parameters()) + list(net_lstm.parameters())\n",
    "optimizer = optim.Adam(params, lr=0.01)\n",
    "episodes = 500\n",
    "\n",
    "(\n",
    "    train_loss,\n",
    "    test_loss,\n",
    "    train_dis,\n",
    "    test_dis,\n",
    "    train_dis_item,\n",
    "    test_dis_item,\n",
    ") = train.train_ConvLSTM(\n",
    "    dataset_loader_train_data,\n",
    "    dataset_loader_test_data,\n",
    "    net_cnn,\n",
    "    net_lstm,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    episodes,\n",
    "    length_trajectory,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499c35e1",
   "metadata": {},
   "source": [
    "### Plot distance and loss over episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08331401",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_euclidean_distance(train_dis, test_dis)\n",
    "plot.plot_losses(train_loss[10:], test_loss[10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91bafac",
   "metadata": {},
   "source": [
    "### Histogram of the distribution shift (for test and training distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955ab276",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set \\n\")\n",
    "plot.histo_distribution_shift(train_dis_item)\n",
    "print(\"Validation set \\n\")\n",
    "plot.histo_distribution_shift(test_dis_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf56dc5",
   "metadata": {},
   "source": [
    "### Histograms showing the training and validation distance distribution (for test and training distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ac87a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.histo_train_val(test_dis_item, train_dis_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bba4297",
   "metadata": {},
   "source": [
    "### Save and load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1421f2b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_m1",
   "language": "python",
   "name": "pytorch_m1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
