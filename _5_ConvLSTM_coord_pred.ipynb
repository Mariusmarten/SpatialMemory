{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ebf1809",
   "metadata": {},
   "source": [
    "# Convolutional LSTM for coordinate prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc293a19",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbd37259",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariuskaestingschaefer/miniforge3/envs/pytorch/lib/python3.8/site-packages/seaborn/rcmod.py:82: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(mpl.__version__) >= \"3.0\":\n",
      "/Users/mariuskaestingschaefer/miniforge3/envs/pytorch/lib/python3.8/site-packages/setuptools/_distutils/version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n",
      "/Users/mariuskaestingschaefer/miniforge3/envs/pytorch/lib/python3.8/site-packages/torch/utils/tensorboard/__init__.py:6: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, '__version__') or LooseVersion(tensorboard.__version__) < LooseVersion('1.15'):\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torchinfo import summary\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# own\n",
    "import common.action as action\n",
    "import common.world as world\n",
    "import common.plot as plot\n",
    "import common.preprocess as preprocess\n",
    "import common.nets as nets\n",
    "import common.train as train\n",
    "import common.tools as tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43c8112",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68951bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets/oracle_data.pickle\", \"rb\") as handle:\n",
    "    oracle_data = pickle.load(handle)\n",
    "\n",
    "with open(\"datasets/oracle_reversed_data.pickle\", \"rb\") as handle:\n",
    "    oracle_reversed_data = pickle.load(handle)\n",
    "\n",
    "with open(\"datasets/oracle_random_data.pickle\", \"rb\") as handle:\n",
    "    oracle_random_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "645e4210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input size is 960 or 1\n",
    "train_imgs = True\n",
    "save_infos = False\n",
    "\n",
    "# preprocessing\n",
    "seq_length = 20\n",
    "training_set_size = 0.80\n",
    "\n",
    "# lstm configuration\n",
    "hidden_size = 200\n",
    "num_layers = 1\n",
    "num_classes = 2\n",
    "save_model = False\n",
    "input_size = 960\n",
    "\n",
    "# training\n",
    "num_epochs = 200\n",
    "learning_rate = 0.01\n",
    "optimizer_type = \"Adam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56995abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sliding_windows(dataset, seq_length, hot_encoding=True):\n",
    "    x_coords = []\n",
    "    y_coords = []\n",
    "\n",
    "    positions = dataset[\"positions\"]\n",
    "    imgs = dataset[\"observations\"]\n",
    "\n",
    "    # preprocess coords\n",
    "    coords = [[i[0], i[2]] for i in positions]\n",
    "\n",
    "    # preprocess images\n",
    "    x_imgs = []\n",
    "    for img in imgs:\n",
    "        img = torch.from_numpy(img).float()\n",
    "        img = img.permute(2, 0, 1)\n",
    "        x_imgs.append(img)\n",
    "    x_imgs_processed = torch.stack(x_imgs)\n",
    "\n",
    "    # actual sliding window\n",
    "    x_imgs = []\n",
    "    for i in range(len(coords) - seq_length - 1):\n",
    "        _x_coords = coords[i : (i + seq_length)]\n",
    "        _x_imgs = x_imgs_processed[i : (i + seq_length)]\n",
    "        _y_coords = coords[i + 1 + seq_length]  # _y = data[i+seq_length]\n",
    "\n",
    "        x_coords.append(_x_coords)\n",
    "        x_imgs.append(_x_imgs)\n",
    "        y_coords.append(_y_coords)\n",
    "\n",
    "    x_imgs = torch.stack(x_imgs)\n",
    "\n",
    "    return np.array(x_coords), x_imgs, np.array(y_coords)  # train, val. data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01af1f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def split(x_acts, x_imgs, y_acts, training_set_size):\n",
    "\n",
    "    train_size = int(len(x_acts) * training_set_size)\n",
    "    test_size = len(x_acts) - train_size\n",
    "    \n",
    "    idx_shuf = list(range(len(x_acts)))\n",
    "    random.shuffle(idx_shuf)\n",
    "\n",
    "    x_acts = [x_acts[i] for i in idx_shuf]\n",
    "    y_acts = [y_acts[i] for i in idx_shuf]\n",
    "    \n",
    "    x_imgs_shuffled = []\n",
    "    for i in idx_shuf:\n",
    "        x_imgs_shuffled.append(x_imgs[i])\n",
    "        \n",
    "    x_imgs = torch.stack(x_imgs_shuffled)\n",
    "    \n",
    "    x_acts = np.asarray(x_acts)\n",
    "    y_acts = np.asarray(y_acts)\n",
    "    \n",
    "    print('types', type(x_acts), type(x_imgs), type(y_acts))\n",
    "    \n",
    "    # (full) data set\n",
    "    dataX_acts = Variable(torch.Tensor(np.array(x_acts)))\n",
    "    dataX_imgs = Variable(torch.Tensor(x_imgs))\n",
    "    dataY_acts = Variable(torch.Tensor(np.array(y_acts)))\n",
    "\n",
    "    # training set\n",
    "    trainX_acts = Variable(torch.Tensor(np.array(x_acts[0:train_size])))\n",
    "    trainX_imgs = Variable(torch.Tensor(np.array(x_imgs[0:train_size])))\n",
    "    trainY_acts = Variable(torch.Tensor(np.array(y_acts[0:train_size])))\n",
    "\n",
    "    # validation set\n",
    "    testX_acts = Variable(torch.Tensor(np.array(x_acts[train_size : len(x_acts)])))\n",
    "    testX_imgs = Variable(torch.Tensor(np.array(x_imgs[train_size : len(x_imgs)])))\n",
    "    testY_acts = Variable(torch.Tensor(np.array(y_acts[train_size : len(y_acts)])))\n",
    "\n",
    "    return (\n",
    "        [dataX_acts, dataX_imgs, dataY_acts],\n",
    "        [trainX_acts, trainX_imgs, trainY_acts],\n",
    "        [testX_acts, testX_imgs, testY_acts],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1450d4",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7acbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_encoding = True\n",
    "\n",
    "# preprocess with sequence length\n",
    "x_coords, x_imgs, y_coords = sliding_windows(\n",
    "    oracle_data, seq_length, hot_encoding\n",
    ")\n",
    "\n",
    "# data, train, test split\n",
    "data, train, test = split(x_acts, x_imgs, y_acts, training_set_size)\n",
    "dataX_acts, dataX_imgs, dataY_acts = data\n",
    "trainX_acts, trainX_imgs, trainY_acts = train\n",
    "testX_acts, testX_imgs, testY_acts = test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3691f1c2",
   "metadata": {},
   "source": [
    "### Initialize models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b32fed10",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainX_imgs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m cnn \u001b[38;5;241m=\u001b[39m nets\u001b[38;5;241m.\u001b[39mCNN(seq_length)\n\u001b[1;32m      3\u001b[0m lstm \u001b[38;5;241m=\u001b[39m nets\u001b[38;5;241m.\u001b[39mLSTM(num_classes, input_size, hidden_size, num_layers, seq_length)\n\u001b[0;32m----> 5\u001b[0m features \u001b[38;5;241m=\u001b[39m cnn(\u001b[43mtrainX_imgs\u001b[49m[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m32\u001b[39m])\n\u001b[1;32m      6\u001b[0m outputs \u001b[38;5;241m=\u001b[39m lstm(features)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCNN input shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, trainX_imgs[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m32\u001b[39m]\u001b[38;5;241m.\u001b[39msize())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainX_imgs' is not defined"
     ]
    }
   ],
   "source": [
    "# initialize network\n",
    "cnn = nets.CNN(seq_length)\n",
    "lstm = nets.LSTM(num_classes, input_size, hidden_size, num_layers, seq_length)\n",
    "\n",
    "features = cnn(trainX_imgs[0:32])\n",
    "outputs = lstm(features)\n",
    "\n",
    "print(\"CNN input shape:\", trainX_imgs[0:32].size())\n",
    "print(\"CNN output shape:\", features.size())\n",
    "\n",
    "print(\"LSTM input shape:\", features.size())\n",
    "print(\"LSTM output shape:\", outputs.size())\n",
    "\n",
    "print(\"Label shape:\", trainY_acts[0:32].size())\n",
    "\n",
    "print(\"SUMMARY CNN \\n\", summary(cnn, trainX_imgs[0:32].size()), \"\\n\")\n",
    "print('SUMMARY LSTM \\n', summary(lstm, (32, 20, 960)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4290c5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plot_losses(train_loss, test_loss, num_epochs):\n",
    "\n",
    "    font = 24\n",
    "    hfont = {\"fontname\": \"Helvetica\"}\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = 20, 6\n",
    "    plt.rcParams[\"axes.titlepad\"] = 13\n",
    "    plt.rcParams[\"xtick.major.pad\"] = \"8\"  # axis distance\n",
    "    plt.rcParams[\"ytick.major.pad\"] = \"8\"\n",
    "\n",
    "    plt.rc(\"xtick\", labelsize=font)\n",
    "    plt.rc(\"ytick\", labelsize=font)\n",
    "\n",
    "    with plt.style.context(\"seaborn-darkgrid\"):\n",
    "\n",
    "        plt.rcParams.update({\"font.size\": font})\n",
    "        plt.plot(test_loss, color=\"red\", linewidth=2, label=\"Validation Loss\")\n",
    "        plt.plot(train_loss, color=\"slategray\", linewidth=2, label=\"Training Loss\")\n",
    "        plt.legend(fontsize=font)\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Loss\")\n",
    "\n",
    "        # plt.savefig('difficult_env_loss_epochs.pdf', bbox_inches=\"tight\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_acc(train_dis, test_dis, num_epochs):\n",
    "\n",
    "    font = 24\n",
    "    hfont = {\"fontname\": \"Helvetica\"}\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = 20, 6\n",
    "    plt.rcParams[\"axes.titlepad\"] = 13\n",
    "    plt.rcParams[\"xtick.major.pad\"] = \"8\"  # axis distance\n",
    "    plt.rcParams[\"ytick.major.pad\"] = \"8\"\n",
    "\n",
    "    plt.rc(\"xtick\", labelsize=font)\n",
    "    plt.rc(\"ytick\", labelsize=font)\n",
    "\n",
    "    plt.rcParams.update({\"font.size\": font})\n",
    "\n",
    "    with plt.style.context(\"seaborn-darkgrid\"):\n",
    "        plt.plot(train_dis, label=\"Training\", linewidth=3, color=\"tab:blue\")\n",
    "        plt.plot(test_dis, c=\"indianred\", label=\"Validation\", linewidth=3)\n",
    "        plt.legend(fontsize=font)\n",
    "        plt.xlabel(\"Epochs\", fontsize=font, **hfont)\n",
    "        plt.ylabel(\"Distance\", fontsize=font, **hfont)\n",
    "\n",
    "        #plt.xlim(xmax=num_epochs + 5, xmin=-2)\n",
    "\n",
    "        # plt.savefig('difficult_env_euclidean_distance_epochs.pdf', bbox_inches=\"tight\")\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7350f086",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def training_loop(trainX_imgs, trainY_acts, testX_imgs, testY_acts, seq_length):\n",
    "    \n",
    "    num_epochs = 200\n",
    "\n",
    "    with tqdm(total=num_epochs, unit=\" Episode\", desc=\"Progress\") as pbar:\n",
    "\n",
    "        seq_length = 20\n",
    "        learning_rate = 0.0001 # 0.0001 ?\n",
    "        hidden_size = 200\n",
    "\n",
    "        cnn = nets.CNN(seq_length)\n",
    "        lstm = nets.LSTM(num_classes, input_size, hidden_size, num_layers, seq_length)\n",
    "        criterion = torch.nn.MSELoss()\n",
    "\n",
    "        params = list(cnn.parameters()) + list(lstm.parameters())\n",
    "        optimizer = torch.optim.Adam(params, lr=learning_rate)\n",
    "\n",
    "        # tracking results\n",
    "        train_loss_lst, test_loss_lst = [], []\n",
    "        train_dis_lst, test_dis_lst = [], []\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            loss_test_col = 0\n",
    "            loss_train_col = 0\n",
    "            test_dis_col = 0\n",
    "            train_dis_col = 0\n",
    "            \n",
    "            optimal_test = len(testY_acts)//32\n",
    "            \n",
    "            # test set\n",
    "            for i in range(optimal_test):\n",
    "                test_dist = 0\n",
    "                start = 32*i\n",
    "                end = 32*(i+1)\n",
    "                # compute validation set performance\n",
    "                with torch.no_grad():\n",
    "                    # choose training style\n",
    "                    if train_imgs:\n",
    "                        features = cnn(testX_imgs[start:end])\n",
    "                    else:\n",
    "                        features = testX_acts\n",
    "                    outputs = lstm(features)\n",
    "            \n",
    "                    # loss\n",
    "                    loss_test = criterion(outputs, testY_acts[start:end])\n",
    "                    loss_test_col += loss_test.item()\n",
    "\n",
    "                    # compute test distance\n",
    "                    values = testY_acts[start:end]\n",
    "                    for idx in range(32):\n",
    "                        test_dist += ((outputs[:][idx][0] - values[idx][0]) ** 2 + (outputs[:][idx][1] - values[idx][1]) ** 2 ) ** 0.5\n",
    "                    test_dist = test_dist / 32\n",
    "                    test_dis_col += test_dist\n",
    "                    \n",
    "            optimal_train = len(trainY_acts)//32\n",
    "            \n",
    "            # training set\n",
    "            for i in range(optimal_train):\n",
    "                train_dist = 0\n",
    "                start = 32*i\n",
    "                end = 32*(i+1)\n",
    "                # choose training style\n",
    "                if train_imgs:\n",
    "                    features = cnn(trainX_imgs[start:end])  # forwarad pass of the cnn\n",
    "                else:\n",
    "                    features = trainX_acts\n",
    "\n",
    "                # forwarad pass of the lstm\n",
    "                outputs = lstm(features)                \n",
    "                optimizer.zero_grad()  # zero the parameter gradients\n",
    "\n",
    "                # loss + optimize\n",
    "                loss_train = criterion(outputs, trainY_acts[start:end])\n",
    "                loss_train.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                loss_train_col += loss_train.item()\n",
    "\n",
    "                # compute test distance\n",
    "                values = trainY_acts[start:end]\n",
    "                for idx in range(32):\n",
    "                    train_dist += ((outputs[idx][0] - values[:][idx][0]) ** 2 + (outputs[idx][1] - values[:][idx][1]) ** 2 ) ** 0.5\n",
    "                train_dist = train_dist / 32\n",
    "                train_dis_col += train_dist\n",
    "\n",
    "            #features = cnn(trainX_imgs[0:32])\n",
    "            #outputs = lstm(features)\n",
    "            #print('predicted', round(outputs[0][0].item(), 5), 'actual', round(trainY_acts[start:end][0][0].item(), 5))\n",
    "            \n",
    "            # display\n",
    "            if epoch % (num_epochs / 10) == 0:\n",
    "                epoch = (4 - len(str(epoch))) * str(0) + str(epoch)\n",
    "                print(\n",
    "                    \"Epoch: %s - Train Loss: %1.3f, Train Dist: %1.3g - Test Loss: %1.3f, Test Dist: %1.3g\"\n",
    "                    % (epoch, loss_train_col/optimal_train, train_dis_col/optimal_train, loss_test_col/optimal_test, test_dis_col/optimal_test)\n",
    "                )\n",
    "            #print(features)\n",
    "\n",
    "            # collect tensorboard logs\n",
    "\n",
    "            # collect plotting logs\n",
    "            train_loss_lst.append(loss_train_col/optimal_train)\n",
    "            test_loss_lst.append(loss_test_col/optimal_test)\n",
    "            train_dis_lst.append(train_dis_col.item()/optimal_train)\n",
    "            test_dis_lst.append(test_dis_col.item()/optimal_test)\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "        plot_losses(train_loss_lst, test_loss_lst, num_epochs)\n",
    "        plot_acc(train_dis_lst, test_dis_lst, num_epochs)\n",
    "        \n",
    "        print(outputs)\n",
    "        print(features)\n",
    "        \n",
    "        print(\"Finished Training\")\n",
    "        \n",
    "        return train_dis_lst, test_dis_lst\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60632095",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dis_lst, test_dis_lst = training_loop(trainX_imgs, trainY_acts, testX_imgs, testY_acts, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8dd6ec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sequence lenth 20 easy environment\n",
      "types <class 'numpy.ndarray'> <class 'torch.Tensor'> <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee908afa6ce54e9f81ddf0f5d6a2f7a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress:   0%|          | 0/200 [00:00<?, ? Episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0000 - Train Loss: 223.129, Train Dist: 20.3 - Test Loss: 246.937, Test Dist: 21.5\n"
     ]
    }
   ],
   "source": [
    "environments = [\n",
    "    'oracle_reversed_data',\n",
    "    'oracle_reversed_random_data_small',\n",
    "    'tmaze_random_reverse_data',\n",
    "]\n",
    "\n",
    "def run_all_environments(environments):\n",
    "\n",
    "    train_acc_col = []\n",
    "    test_acc_col = []\n",
    "    hot_encoding = True\n",
    "    seq_length = 20\n",
    "\n",
    "    for idx, data in enumerate(environments):\n",
    "        \n",
    "        for i in range(1):\n",
    "            \n",
    "            if data == 'oracle_reversed_data':\n",
    "                with open(\"datasets/oracle_reversed_data.pickle\", \"rb\") as handle:\n",
    "                    data_set = pickle.load(handle)\n",
    "            if data == 'oracle_reversed_random_data_small':\n",
    "                with open(\"datasets/oracle_reversed_random_data_small.pickle\", \"rb\") as handle:\n",
    "                    data_set = pickle.load(handle)\n",
    "            if data == 'tmaze_random_reverse_data':\n",
    "                with open(\"datasets/tmaze_random_reverse_data.pickle\", \"rb\") as handle:\n",
    "                    data_set = pickle.load(handle)\n",
    "            \n",
    "            print(\"\")\n",
    "            if idx == 0:\n",
    "                print(\"sequence lenth\", seq_length, \"easy environment\")\n",
    "            if idx == 1:\n",
    "                print(\"sequence lenth\", seq_length, \"medium environment\")\n",
    "            if idx == 2:\n",
    "                print(\"sequence lenth\", seq_length, \"difficult environment\")\n",
    "            \n",
    "            shuffle = True\n",
    "            \n",
    "            # preprocess with sequence length\n",
    "            x_coords, x_imgs, y_coords = sliding_windows(\n",
    "                data_set, seq_length, hot_encoding\n",
    "            )\n",
    "\n",
    "            # data, train, test split\n",
    "            data, train, test = split(x_coords, x_imgs, y_coords, training_set_size)\n",
    "            dataX_acts, dataX_imgs, dataY_acts = data\n",
    "            trainX_acts, trainX_imgs, trainY_acts = train\n",
    "            testX_acts, testX_imgs, testY_acts = test\n",
    "            \n",
    "            train_acc, test_acc = training_loop(trainX_imgs, trainY_acts, testX_imgs, testY_acts, seq_length)\n",
    "            \n",
    "            train_acc_col.append(train_acc)\n",
    "            test_acc_col.append(test_acc)\n",
    "            \n",
    "    return train_acc_col, test_acc_col\n",
    "\n",
    "train_acc, test_acc = run_all_environments(environments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09309a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets/tmaze_random_reverse_data.pickle\", \"rb\") as handle:\n",
    "    data_set = pickle.load(handle)\n",
    "\n",
    "x_coords, x_imgs, y_coords = sliding_windows(data_set, seq_length, hot_encoding)\n",
    "\n",
    "print(y_coords)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38ebc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "font = 24\n",
    "hfont = {\"fontname\": \"Helvetica\"}\n",
    "\n",
    "# plt.rcParams[\"figure.figsize\"] = 25, 5.5\n",
    "plt.rcParams.update({\"font.size\": font})\n",
    "plt.rcParams[\"axes.titlepad\"] = 13\n",
    "plt.rcParams[\"xtick.major.pad\"] = \"8\"  # axis distance\n",
    "plt.rcParams[\"ytick.major.pad\"] = \"8\"\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "with plt.style.context(\"seaborn-darkgrid\"):\n",
    "    \n",
    "    plt.rc(\"xtick\", labelsize=font)\n",
    "    plt.rc(\"ytick\", labelsize=font)\n",
    "\n",
    "    plt.title(\"Training set\", fontsize=font)\n",
    "    plt.ylabel(\"Accuracy\", fontsize=font, **hfont)\n",
    "    plt.xlabel(\"Epochs\", fontsize=font, **hfont)\n",
    "    \n",
    "    # easy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    (y1,) = plt.plot(\n",
    "        train_acc[0],\n",
    "        linestyle=\"solid\",\n",
    "        c=\"tab:blue\",\n",
    "        label=\"Easy\",\n",
    "        linewidth=4.0,\n",
    "    )\n",
    "    (y2,) = plt.plot(\n",
    "        train_acc[1],\n",
    "        c=\"slategray\",\n",
    "        linestyle=\"solid\",\n",
    "        label=\"Medium\",\n",
    "        linewidth=4.0,\n",
    "    )\n",
    "    (y3,) = plt.plot(\n",
    "        train_acc[2],\n",
    "        c=\"darkseagreen\",\n",
    "        linestyle=\"solid\",\n",
    "        label=\"Difficult\",\n",
    "        linewidth=4.0,\n",
    "    )\n",
    "    \n",
    "    #plt.ylim(ymax=1.05, ymin=0)\n",
    "    #plt.yticks(np.arange(0, 1.05, 0.2))\n",
    "    plt.ylabel(\"Euclidean Distance\", fontsize=font, **hfont)\n",
    "    plt.xlabel(\"epochs\", fontsize=font, **hfont)\n",
    "    plt.title(\"Training set\", fontsize=font, **hfont)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(\n",
    "        test_acc[0],\n",
    "        linestyle=\"solid\",\n",
    "        c=\"tab:blue\",\n",
    "        label=\"Easy\",\n",
    "        linewidth=4.0,\n",
    "    )\n",
    "    plt.plot(\n",
    "        test_acc[1],\n",
    "        c=\"slategray\",\n",
    "        linestyle=\"solid\",\n",
    "        label=\"Medium\",\n",
    "        linewidth=4.0,\n",
    "    )\n",
    "    plt.plot(\n",
    "        test_acc[2],\n",
    "        c=\"darkseagreen\",\n",
    "        linestyle=\"solid\",\n",
    "        label=\"Difficult\",\n",
    "        linewidth=4.0,\n",
    "    )\n",
    "\n",
    "    #plt.ylim(ymax=1.05, ymin=0)\n",
    "    #plt.yticks(np.arange(0, 1.05, 0.2))\n",
    "    plt.xlabel(\"epochs\", fontsize=font, **hfont)\n",
    "    plt.title(\"Validation set\", fontsize=font, **hfont)\n",
    "\n",
    "plt.legend(\n",
    "    handles=[y1, y2, y3],\n",
    "    bbox_to_anchor=(1.05, 1),\n",
    "    loc=\"upper left\",\n",
    "    frameon=False,\n",
    ")\n",
    "plt.savefig(\"ConvLSTM_action_results.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ceed954",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795a968b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed57693a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "params = list(net_cnn.parameters()) + list(net_lstm.parameters())\n",
    "optimizer = optim.Adam(params, lr=0.01)\n",
    "episodes = 500\n",
    "\n",
    "(\n",
    "    train_loss,\n",
    "    test_loss,\n",
    "    train_dis,\n",
    "    test_dis,\n",
    "    train_dis_item,\n",
    "    test_dis_item,\n",
    ") = train.train_ConvLSTM(\n",
    "    dataset_loader_train_data,\n",
    "    dataset_loader_test_data,\n",
    "    net_cnn,\n",
    "    net_lstm,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    episodes,\n",
    "    length_trajectory,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499c35e1",
   "metadata": {},
   "source": [
    "### Plot distance and loss over episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08331401",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_euclidean_distance(train_dis, test_dis)\n",
    "plot.plot_losses(train_loss[10:], test_loss[10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91bafac",
   "metadata": {},
   "source": [
    "### Histogram of the distribution shift (for test and training distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955ab276",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set \\n\")\n",
    "plot.histo_distribution_shift(train_dis_item)\n",
    "print(\"Validation set \\n\")\n",
    "plot.histo_distribution_shift(test_dis_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf56dc5",
   "metadata": {},
   "source": [
    "### Histograms showing the training and validation distance distribution (for test and training distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ac87a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.histo_train_val(test_dis_item, train_dis_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bba4297",
   "metadata": {},
   "source": [
    "### Save and load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1421f2b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_m1",
   "language": "python",
   "name": "pytorch_m1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
