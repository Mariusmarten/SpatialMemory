{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a3720e1",
   "metadata": {},
   "source": [
    "### Single-input Network - PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1447aa5f",
   "metadata": {},
   "source": [
    "- split jupyter notebooks (dataset creation, network training)\n",
    "\n",
    "###### waypoint executer\n",
    "- write program that finds path between waypoints\n",
    "\n",
    "###### training\n",
    "- make use of tensorboard\n",
    "- load and save models\n",
    "\n",
    "###### testing (most important)\n",
    "- Classification network to predict coordinates\n",
    "- Multiple action prediction (How to shuffle data for long seq.?) /  create dataset with n steps appart\n",
    "- Siam network: https://colab.research.google.com/drive/1sn7BDKVvi8-Ng37gvfyNw8OCf8kZY91o?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21debb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Imports external and own libraries\n",
    "'''\n",
    "\n",
    "import pickle\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "# own\n",
    "import collector\n",
    "import action\n",
    "import world\n",
    "import plot\n",
    "import preprocess\n",
    "import nets\n",
    "import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15326afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf1b408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23fd605",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Use Dataloader to make the data ready for the training loop\n",
    "'''\n",
    "train_data, test_data = preprocess.split_data(oracle_random_data, 0.8)\n",
    "\n",
    "# preprocess trainingset \n",
    "oracle_train_data = preprocess.ActionObservationDataset(train_data)\n",
    "oracle_test_data = preprocess.ActionObservationDataset(test_data)\n",
    "\n",
    "# build dataloader (tensor format)\n",
    "batch_size = 64\n",
    "dataset_loader_train_data = DataLoader(oracle_train_data, batch_size=batch_size, shuffle=True)\n",
    "dataset_loader_test_data = DataLoader(oracle_test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c48671e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Visualize one batch\n",
    "'''\n",
    "\n",
    "# next data part\n",
    "dataiter = iter(dataset_loader)\n",
    "# plot 64 examples\n",
    "images, labels = dataiter.next()\n",
    "plot.plot_64_observations(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5780b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Feed-forward network\n",
    "'''\n",
    "\n",
    "forward = nets.Forward()\n",
    "summary(forward, (3,32,32))\n",
    "\n",
    "forward = nets.Forward_Large()\n",
    "summary(forward, (3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ed0edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Train the network\n",
    "'''\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(forward.parameters(), lr=0.3, momentum=0.9) # for small one 0.01 works well\n",
    "\n",
    "episodes = 10\n",
    "net, test_loss, train_loss, test_acc, train_acc  = train.train(dataset_loader_train_data, dataset_loader_test_data, forward, criterion, optimizer, episodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4436f524",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Plot loss and accuracy curves for training and test set\n",
    "'''\n",
    "\n",
    "plot.plot_losses(test_loss, train_loss)\n",
    "plot.plot_acc(test_acc, train_acc, smooth=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d09bed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def show_example_classificataions(dataset, net, amount=5):\n",
    "    classes_expl = {0: 'turn left', 1: 'turn right', 2: 'walk forwards', 3: 'walk backwards'} \n",
    "    \n",
    "    # calculate total accuracy on training data\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in dataset:\n",
    "            images, labels = data\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = net(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('GroundTruth: ', ', '.join(f'{classes_expl[int(labels[j])]}' for j in range(amount)))\n",
    "    print('Predicted: ', ', '.join(f'{classes_expl[int(predicted[j])]}' for j in range(amount)), '\\n')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(dataset, network, save=False):\n",
    "    classes_expl = {0: 'turn left', 1: 'turn right', 2: 'walk forwards', 3: 'walk backwards'} \n",
    "    \n",
    "    # plot confusion matrix\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    # iterate over test data\n",
    "    for inputs, labels in dataset_loader_train_data:\n",
    "            output = net(inputs) # Feed pass through network\n",
    "\n",
    "            output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "            y_pred.extend(output) # Save Prediction\n",
    "\n",
    "            labels = labels.data.cpu().numpy()\n",
    "            y_true.extend(labels) # Save Truth\n",
    "\n",
    "    # Build confusion matrix\n",
    "    classes = list(set(labels))\n",
    "    cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix) *10, index = [classes_expl[i] for i in classes],\n",
    "                         columns = [classes_expl[i] for i in classes])\n",
    "    plt.figure(figsize = (12,7))\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    sn.heatmap(df_cm, annot=True)\n",
    "    plt.suptitle('Confusion matrix')\n",
    "    plt.ylabel('True labels')\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.show()\n",
    "\n",
    "    if save:\n",
    "        plt.savefig('output.png')\n",
    "\n",
    "show_example_classificataions(dataset_loader_train_data, net, amount=8)\n",
    "plot_confusion_matrix(dataset_loader_train_data, net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a992dc63",
   "metadata": {},
   "source": [
    "### Multi-input Network - Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210655a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/zaidalyafeai/Machine-Learning/blob/master/Multi-input%20Network%20Pytorch.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
