{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "333cbd0d",
   "metadata": {},
   "source": [
    "### Feed-forward coordinate prediction (DualOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee23f3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariuskaestingschaefer/miniforge3/envs/pytorch/lib/python3.8/site-packages/seaborn/rcmod.py:82: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(mpl.__version__) >= \"3.0\":\n",
      "/Users/mariuskaestingschaefer/miniforge3/envs/pytorch/lib/python3.8/site-packages/setuptools/_distutils/version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n",
      "/Users/mariuskaestingschaefer/miniforge3/envs/pytorch/lib/python3.8/site-packages/torch/utils/tensorboard/__init__.py:6: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, '__version__') or LooseVersion(tensorboard.__version__) < LooseVersion('1.15'):\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Imports external and own libraries\n",
    "'''\n",
    "\n",
    "import pickle\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "# own\n",
    "import collector\n",
    "import action\n",
    "import world\n",
    "import plot\n",
    "import preprocess\n",
    "import nets\n",
    "import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05c2af4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Load data with pickle (deserialize)\n",
    "'''\n",
    "with open('datasets/oracle_data.pickle', 'rb') as handle:\n",
    "    oracle_data = pickle.load(handle)\n",
    "\n",
    "with open('datasets/oracle_reversed_data.pickle', 'rb') as handle:\n",
    "    oracle_reversed_data = pickle.load(handle)\n",
    "\n",
    "with open('datasets/oracle_random_data.pickle', 'rb') as handle:\n",
    "    oracle_random_data = pickle.load(handle)\n",
    "\n",
    "with open('datasets/oracle_reversed_random_data.pickle', 'rb') as handle:\n",
    "    oracle_reversed_random_data = pickle.load(handle)\n",
    "    \n",
    "with open('datasets/random_data.pickle', 'rb') as handle:\n",
    "    random_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73c02f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 28, 28]             456\n",
      "         MaxPool2d-2            [-1, 6, 14, 14]               0\n",
      "            Conv2d-3           [-1, 16, 10, 10]           2,416\n",
      "         MaxPool2d-4             [-1, 16, 5, 5]               0\n",
      "            Linear-5                  [-1, 120]          48,120\n",
      "            Linear-6                   [-1, 84]          10,164\n",
      "            Linear-7                    [-1, 1]              85\n",
      "            Linear-8                  [-1, 120]          48,120\n",
      "            Linear-9                   [-1, 84]          10,164\n",
      "           Linear-10                    [-1, 1]              85\n",
      "================================================================\n",
      "Total params: 119,610\n",
      "Trainable params: 119,610\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.06\n",
      "Params size (MB): 0.46\n",
      "Estimated Total Size (MB): 0.53\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "pred_coordinates = nets.DualOutput()\n",
    "summary(pred_coordinates, (3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5efd2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Use Dataloader to make the data ready for the training loop\n",
    "'''\n",
    "train_data, test_data = preprocess.split_data(oracle_random_data, 0.8)\n",
    "\n",
    "# preprocess trainingset \n",
    "oracle_train_data = preprocess.ObtainDataset(train_data, 'observations', 'positions')\n",
    "oracle_test_data = preprocess.ObtainDataset(test_data, 'observations', 'positions')\n",
    "\n",
    "# build dataloader (tensor format)\n",
    "batch_size = 64\n",
    "dataset_loader_train_data = DataLoader(oracle_train_data, batch_size=batch_size, shuffle=True)\n",
    "dataset_loader_test_data = DataLoader(oracle_test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfcf85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c3e0f5e9284bc1a0b39f3bfb6f3453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress:   0%|          | 0/500 [00:00<?, ? Episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 117.0, Train Acc: 4.102 %,  Test Loss: 117.8, Test Acc: 4.184 %,\n",
      "Epoch: 11, Train Loss: 95.47, Train Acc: 4.423 %,  Test Loss: 96.19, Test Acc: 4.453 %,\n",
      "Epoch: 21, Train Loss: 90.86, Train Acc: 4.976 %,  Test Loss: 88.74, Test Acc: 5.619 %,\n",
      "Epoch: 31, Train Loss: 85.03, Train Acc: 4.304 %,  Test Loss: 85.13, Test Acc: 5.499 %,\n",
      "Epoch: 41, Train Loss: 79.43, Train Acc: 4.214 %,  Test Loss: 81.98, Test Acc: 3.616 %,\n",
      "Epoch: 51, Train Loss: 75.59, Train Acc: 4.647 %,  Test Loss: 75.57, Test Acc: 5.081 %,\n",
      "Epoch: 61, Train Loss: 71.55, Train Acc: 4.356 %,  Test Loss: 75.8, Test Acc: 4.543 %,\n",
      "Epoch: 71, Train Loss: 66.94, Train Acc: 4.759 %,  Test Loss: 69.91, Test Acc: 3.736 %,\n",
      "Epoch: 81, Train Loss: 64.19, Train Acc: 4.999 %,  Test Loss: 69.28, Test Acc: 4.782 %,\n",
      "Epoch: 91, Train Loss: 60.91, Train Acc: 5.088 %,  Test Loss: 64.98, Test Acc: 5.32 %,\n",
      "Epoch: 101, Train Loss: 59.27, Train Acc: 5.335 %,  Test Loss: 63.45, Test Acc: 5.409 %,\n",
      "Epoch: 111, Train Loss: 58.11, Train Acc: 5.626 %,  Test Loss: 66.53, Test Acc: 5.32 %,\n",
      "Epoch: 121, Train Loss: 56.63, Train Acc: 5.678 %,  Test Loss: 61.13, Test Acc: 4.901 %,\n",
      "Epoch: 131, Train Loss: 56.19, Train Acc: 5.424 %,  Test Loss: 60.77, Test Acc: 5.32 %,\n",
      "Epoch: 141, Train Loss: 55.23, Train Acc: 5.678 %,  Test Loss: 58.89, Test Acc: 4.991 %,\n",
      "Epoch: 151, Train Loss: 54.82, Train Acc: 5.619 %,  Test Loss: 58.82, Test Acc: 5.409 %,\n",
      "Epoch: 161, Train Loss: 54.29, Train Acc: 5.783 %,  Test Loss: 56.6, Test Acc: 6.067 %,\n",
      "Epoch: 171, Train Loss: 53.92, Train Acc: 6.052 %,  Test Loss: 57.67, Test Acc: 5.2 %,\n",
      "Epoch: 181, Train Loss: 53.66, Train Acc: 6.119 %,  Test Loss: 57.16, Test Acc: 6.186 %,\n",
      "Epoch: 191, Train Loss: 53.59, Train Acc: 6.366 %,  Test Loss: 56.82, Test Acc: 6.306 %,\n",
      "Epoch: 201, Train Loss: 53.01, Train Acc: 6.052 %,  Test Loss: 56.02, Test Acc: 6.216 %,\n",
      "Epoch: 211, Train Loss: 53.06, Train Acc: 6.209 %,  Test Loss: 56.56, Test Acc: 6.246 %,\n",
      "Epoch: 221, Train Loss: 52.78, Train Acc: 6.321 %,  Test Loss: 55.99, Test Acc: 5.649 %,\n",
      "Epoch: 231, Train Loss: 52.87, Train Acc: 6.112 %,  Test Loss: 56.95, Test Acc: 5.26 %,\n",
      "Epoch: 241, Train Loss: 52.76, Train Acc: 6.411 %,  Test Loss: 56.5, Test Acc: 6.784 %,\n",
      "Epoch: 251, Train Loss: 52.8, Train Acc: 6.403 %,  Test Loss: 55.09, Test Acc: 6.665 %,\n",
      "Epoch: 261, Train Loss: 52.42, Train Acc: 6.411 %,  Test Loss: 55.88, Test Acc: 6.216 %,\n",
      "Epoch: 271, Train Loss: 52.58, Train Acc: 6.829 %,  Test Loss: 56.79, Test Acc: 5.2 %,\n",
      "Epoch: 281, Train Loss: 52.69, Train Acc: 6.485 %,  Test Loss: 57.63, Test Acc: 5.26 %,\n",
      "Epoch: 291, Train Loss: 52.35, Train Acc: 6.754 %,  Test Loss: 56.09, Test Acc: 5.678 %,\n",
      "Epoch: 301, Train Loss: 52.43, Train Acc: 6.642 %,  Test Loss: 55.1, Test Acc: 7.053 %,\n",
      "Epoch: 311, Train Loss: 52.34, Train Acc: 6.493 %,  Test Loss: 55.98, Test Acc: 6.754 %,\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Train the network\n",
    "- obtained with RMS, lr=0.0005, 200 episodes: train acc. 4% (73 loss), test acc. 4%\n",
    "- obtained with RMS, lr=0.0005, 300 episodes: train acc. 5% (60 loss), test acc. 6%\n",
    "- obtained with RMS, lr=0.0005, 400 episodes: train acc. 6% (56 loss), test acc. 6%\n",
    "\n",
    "- what with a lr. of 0.001?\n",
    "Learning then stagnates; decrease learning rate?\n",
    "Change weight initialization?\n",
    "'''\n",
    "\n",
    "criterion = nn.MSELoss() # CrossEntropyLoss\n",
    "optimizer = optim.RMSprop(pred_coordinates.parameters(), lr=0.001) # RMSprop, Adam, SGD\n",
    "\n",
    "episodes = 500\n",
    "pred_coordinates, train_loss, test_loss, train_acc, test_acc  = train.DualOutput(dataset_loader_train_data, dataset_loader_test_data, \n",
    "                                                                           pred_coordinates, criterion, optimizer, episodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20082407",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Plot loss and accuracy curves for training and test set\n",
    "'''\n",
    "\n",
    "plot.plot_losses(train_loss, test_loss)\n",
    "plot.plot_acc(train_acc, test_acc, smooth=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293d099e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Save and load model\n",
    "'''\n",
    "import torch \n",
    "\n",
    "torch.save(net, 'models/DualOutput2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6138cf18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
